import streamlit as st
import time
from anthropic import Anthropic
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import pandas as pd
import logging
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import plotly.express as px
import plotly.graph_objects as go
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter, A4
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib import colors
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Image, Spacer, Paragraph
from reportlab.lib.units import inch
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.pdfbase.pdfmetrics import registerFontFamily
import io
import re
import os
from dotenv import load_dotenv

# Streamlit Cloudì—ì„œ Chrome ì„¤ì¹˜ í•¨ìˆ˜
def install_chrome():
    try:
        subprocess.run(['apt-get', 'update'], check=True)
        subprocess.run(['apt-get', 'install', '-y', 'chromium-browser'])
    except Exception as e:
        st.error(f"Chrome ì„¤ì¹˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Streamlit Cloud í™˜ê²½ì—ì„œ Chrome ì„¤ì¹˜
if 'STREAMLIT_CLOUD' in os.environ:
    import subprocess
    install_chrome()

class YeoshinScraper:
    def __init__(self):
        self.results = []
        self.driver = None
        self.setup_logging()
        
    def setup_logging(self):
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        
    def setup_driver(self):
        try:
            options = webdriver.ChromeOptions()
            # ì„±ëŠ¥ ìµœì í™” ì˜µì…˜ë“¤
            options.add_argument('--headless')            
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-extensions')
            options.add_argument('--disable-notifications')
            options.add_argument('--disable-logging')
            options.add_argument('--log-level=3')
            options.add_argument('--disable-default-apps')
            options.add_argument('--disable-infobars')
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_argument('--start-maximized')  
            options.add_argument('--disable-gpu')
            options.add_argument('--disable-popup-blocking')
            options.add_argument('--blink-settings=imagesEnabled=false')
            options.add_argument('--window-size=1920,1080')

            # ë©”ëª¨ë¦¬ ê´€ë ¨ ì„¤ì •
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--no-zygote')
            options.add_argument('--disable-accelerated-2d-canvas')
            options.add_argument('--disable-webgl')

            options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            # Streamlit Cloud í™˜ê²½ì¼ ë•Œì˜ ì¶”ê°€ ì„¤ì •
            if 'STREAMLIT_CLOUD' in os.environ:
                options.binary_location = '/usr/bin/chromium-browser'
                options.add_argument('--no-sandbox')
                options.add_argument('--disable-dev-shm-usage')
            
            if 'STREAMLIT_CLOUD' in os.environ:
                self.driver = webdriver.Chrome(options=options)
            else:
                service = Service(ChromeDriverManager().install())
                self.driver = webdriver.Chrome(service=service, options=options)
                
            self.driver.set_page_load_timeout(30)
            self.wait = WebDriverWait(self.driver, 15)

            # ë¹ˆ í˜ì´ì§€ ì ‘ì†
            self.driver.get("https://www.yeoshin.co.kr")
            time.sleep(2)

            # ë¡œê·¸ì¸ ê´€ë ¨ ì¿ í‚¤ ì„¤ì •
            cookies = [
                {"name": "LOGIN_INFO", "value": os.getenv("LOGIN_INFO")},
                {"name": "HSID", "value": os.getenv("HSID")},
                {"name": "SSID", "value": os.getenv("SSID")},
                {"name": "APISID", "value": os.getenv("APISID")},
                {"name": "SAPISID", "value": os.getenv("SAPISID")},
                {"name": "SID", "value": os.getenv("SID")},
                {"name": "_kau", "value": os.getenv("KAU")},
                {"name": "_kahai", "value": os.getenv("KAHAI")},
                {"name": "_karmt", "value": os.getenv("KARMT")},
                {"name": "_kawlt", "value": os.getenv("KAWLT")},
                {"name": "access_token", "value": os.getenv("ACCESS_TOKEN")}
            ]

            for cookie in cookies:
                if cookie["value"] is None:
                    logging.warning(f"ì¿ í‚¤ ê°’ì´ ì—†ìŠµë‹ˆë‹¤: {cookie['name']}")
                    continue
                    
                cookie.update({
                    "domain": ".yeoshin.co.kr",
                    "path": "/"
                })
                self.driver.add_cookie(cookie)

            self.driver.refresh()
            time.sleep(2)

        except Exception as e:
            logging.error(f"Driver ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise

    def wait_for_page_load(self, timeout=15):
        try:
            WebDriverWait(self.driver, timeout).until(
                lambda d: d.execute_script("return document.readyState") == "complete"
            )
            time.sleep(2)
        except TimeoutException:
            logging.warning("í˜ì´ì§€ ë¡œë”© ì‹œê°„ ì´ˆê³¼")

    def scroll_to_load_all(self):
        SCROLL_PAUSE_TIME = 1
        last_height = self.driver.execute_script("return document.body.scrollHeight")
        
        for _ in range(3):
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(SCROLL_PAUSE_TIME)
            
            try:
                WebDriverWait(self.driver, 10).until(
                    lambda driver: driver.execute_script("return document.body.scrollHeight") > last_height
                )
            except TimeoutException:
                break
                
            new_height = self.driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height

    def search_keyword(self, keyword, progress_bar):
        try:
            search_url = f"https://www.yeoshin.co.kr/search/category?q={keyword}&tab=events"
            self.driver.get(search_url)
            self.wait_for_page_load()
            progress_bar.progress(0.2)
            
            time.sleep(5)
            self.scroll_to_load_all()
            progress_bar.progress(0.3)
            
        except Exception as e:
            logging.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    def get_event_details(self, item, progress_value, progress_bar):
        main_window = self.driver.current_window_handle
        try:
            # ë³‘ì› ì´ë¦„ê³¼ ì§€ì—­ ì •ë³´ ì¶”ì¶œ
            spans = item.find_elements(By.CSS_SELECTOR, "span")
            if len(spans) >= 3:
                hospital_name = spans[0].text.strip()
                location = item.find_element(
                    By.XPATH,
                    './/article/section[2]/div/span[2]'
                ).text.strip()
                
                # ì´ë²¤íŠ¸ëª… ì¶”ì¶œ
                event_name = item.find_element(
                    By.XPATH,
                    './/article/section[2]/section[1]/h2'
                ).text.strip()
                
                # ìƒì„¸ í˜ì´ì§€ ë§í¬ ìš”ì†Œ ì°¾ê¸° ë° í´ë¦­
                article = item.find_element(By.TAG_NAME, "article")
                self.driver.execute_script("arguments[0].click();", article)
                time.sleep(3)
                
                # ìƒˆ ì°½ìœ¼ë¡œ ì „í™˜
                new_window = [handle for handle in self.driver.window_handles if handle != main_window][0]
                self.driver.switch_to.window(new_window)
                time.sleep(3)

                # ìƒì„¸ í˜ì´ì§€ URL ê°€ì ¸ì˜¤ê¸°
                detail_link = self.driver.current_url
                
                # í‰ì , ë¦¬ë·°ìˆ˜, ìŠ¤í¬ë©ìˆ˜, ë¬¸ì˜ìˆ˜ ì¶”ì¶œ
                try:
                    rating_element = self.driver.find_element(
                        By.XPATH,
                        '//*[@id="ct-view"]/div/div/div/div[2]/div[1]/article/section/div[2]/div/div/span'
                    )
                    rating = rating_element.text.strip()
                except NoSuchElementException:
                    rating = "N/A"
                
                try:
                    review_count_element = self.driver.find_element(
                        By.XPATH,
                        '//*[@id="ct-view"]/div/div/div/div[2]/div[1]/article/section/div[2]/div/span'
                    )
                    review_count = review_count_element.text.strip()
                    # 'í›„ê¸°' í…ìŠ¤íŠ¸ ì œê±°í•˜ê³  ìˆ«ìë§Œ ì¶”ì¶œ
                    review_count = re.sub(r'[^0-9]', '', review_count)
                except NoSuchElementException:
                    review_count = "N/A"
                
                try:
                    scrap_element = self.driver.find_element(
                        By.XPATH,
                        '//*[@id="ct-view"]/div/div/section/div[1]/div/p'
                    )
                    scrap_count = scrap_element.text.strip()
                except NoSuchElementException:
                    scrap_count = "N/A"
                
                try:
                    inquiry_element = self.driver.find_element(
                        By.XPATH,
                        '//*[@id="ct-view"]/div/div/div/div[2]/div[4]/div[1]/div/p[2]'
                    )
                    inquiry_count = inquiry_element.text.strip()
                except NoSuchElementException:
                    inquiry_count = "N/A"

                # ì˜µì…˜ ì •ë³´ ìˆ˜ì§‘
                options_data = []
                try:
                    # ì „ì²´ë³´ê¸° ë²„íŠ¼ ì°¾ê¸° ë° í´ë¦­
                    view_all_button = WebDriverWait(self.driver, 10).until(
                        EC.element_to_be_clickable((
                            By.XPATH,
                            '//*[@id="ct-view"]/div/div/div[1]/div[2]/div[2]/div[position()>=2 and position()<=4]/div/div[2]/p'
                        ))
                    )
                    self.driver.execute_script("arguments[0].click();", view_all_button)
                    time.sleep(2)
                    
                    # ëª¨ë‹¬ì—ì„œ ì˜µì…˜ ì •ë³´ ìˆ˜ì§‘
                    options_base_xpath = '//*[@id="ct-view"]/div/div/div[2]/div/div/div/div[2]/div[2]'
                    options = WebDriverWait(self.driver, 10).until(
                        EC.presence_of_all_elements_located((By.XPATH, f"{options_base_xpath}/div"))
                    )
                    
                    for i in range(1, len(options) + 1):
                        try:
                            current_option_xpath = f"{options_base_xpath}/div[{i}]"
                            option_name = self.driver.find_element(
                                By.XPATH,
                                f"{current_option_xpath}/div/p"
                            ).text.strip()
                            price = self.driver.find_element(
                                By.XPATH,
                                f"{current_option_xpath}/p"
                            ).text.strip()
                            
                            if option_name and price:
                                options_data.append({
                                    'hospital_name': hospital_name,
                                    'location': location,
                                    'event_name': event_name,
                                    'option_name': option_name,
                                    'price': price,
                                    'rating': rating,
                                    'review_count': review_count,
                                    'scrap_count': scrap_count,
                                    'inquiry_count': inquiry_count,
                                    'detail_link': detail_link
                                })
                        except Exception as e:
                            logging.error(f"ê°œë³„ ì˜µì…˜ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                            continue
                            
                except TimeoutException:
                    logging.info("ì „ì²´ë³´ê¸° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì˜µì…˜ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
                    # ê¸°ë³¸ ì˜µì…˜ ì •ë³´ ìˆ˜ì§‘
                    try:
                        options_container = WebDriverWait(self.driver, 10).until(
                            EC.presence_of_element_located((
                                By.XPATH,
                                '//*[@id="ct-view"]/div/div/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]'
                            ))
                        )
                        option_elements = options_container.find_elements(By.XPATH, './div/div')
                        
                        for option in option_elements:
                            try:
                                divs = option.find_elements(By.CSS_SELECTOR, "div")
                                if len(divs) >= 2:
                                    option_name = divs[0].text.strip()
                                    option_price = divs[1].text.strip()
                                    
                                    if option_name and option_price:
                                        options_data.append({
                                            'hospital_name': hospital_name,
                                            'location': location,
                                            'event_name': event_name,
                                            'option_name': option_name,
                                            'price': option_price,
                                            'rating': rating,
                                            'review_count': review_count,
                                            'scrap_count': scrap_count,
                                            'inquiry_count': inquiry_count,
                                            'detail_link': detail_link
                                        })
                            except Exception as e:
                                logging.error(f"ê¸°ë³¸ ì˜µì…˜ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                                continue
                    except TimeoutException:
                        logging.error("ê¸°ë³¸ ì˜µì…˜ ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                # ì°½ ë‹«ê³  ì›ë˜ ì°½ìœ¼ë¡œ ë³µê·€
                self.driver.close()
                self.driver.switch_to.window(main_window)
                time.sleep(2)
                
                progress_bar.progress(progress_value)
                return options_data
            
        except Exception as e:
            logging.error(f"ì´ë²¤íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            if len(self.driver.window_handles) > 1:
                self.driver.close()
                self.driver.switch_to.window(main_window)
            time.sleep(2)
            return []

    def scrape_data(self, keyword, progress_bar):
        try:
            self.setup_driver()
            self.search_keyword(keyword, progress_bar)
            
            # ê²€ìƒ‰ ê²°ê³¼ ë¡œë”© ëŒ€ê¸°
            time.sleep(3)
            
            # ì»¨í…Œì´ë„ˆ ì°¾ê¸° ì „ì— í•œ ë²ˆ ë” ìŠ¤í¬ë¡¤
            self.scroll_to_load_all()
            
            events_container = WebDriverWait(self.driver, 15).until(
                EC.presence_of_element_located((
                    By.CSS_SELECTOR,
                    "#ct-view > div > main > article > section:nth-child(2) > section"
                ))
            )
            
            event_items = events_container.find_elements(By.XPATH, "./div")
            total_items = len(event_items)
            
            if total_items == 0:
                logging.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()
                
            events_data = []
            for idx, item in enumerate(event_items, 1):
                progress_value = 0.3 + (0.7 * (idx / total_items))
                item_data = self.get_event_details(item, progress_value, progress_bar)
                if item_data:
                    events_data.extend(item_data)
            
            return pd.DataFrame(events_data)
            
        except Exception as e:
            logging.error(f"ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return pd.DataFrame()
        finally:
            if self.driver:
                self.driver.quit()

def create_visualizations(df):
    # ê°€ê²© ë°ì´í„° ì „ì²˜ë¦¬
    def clean_price(price_str):
        try:
            numbers = re.findall(r'\d+', price_str)
            if numbers:
                return int(''.join(numbers))
            return None
        except:
            return None
    
    # ê°€ê²© ë°ì´í„° ì •ì œ
    df_viz = df.copy()
    df_viz['price_cleaned'] = df_viz['ê°€ê²©'].apply(clean_price)
    df_viz = df_viz[df_viz['price_cleaned'].notna()]
    
    # ê° ë³‘ì›ë³„ë¡œ ì²« ë²ˆì§¸ ì˜µì…˜ë§Œ ì„ íƒ
    df_first_options = df_viz.groupby(['ë³‘ì›ëª…', 'ìœ„ì¹˜']).first().reset_index()
    
    # ì§€ì—­ë³„ í‰ê·  ê°€ê²© ê³„ì‚° (ì²« ë²ˆì§¸ ì˜µì…˜ë§Œ ì‚¬ìš©)
    fig_price = px.bar(
        df_first_options.groupby('ìœ„ì¹˜')['price_cleaned'].mean().reset_index(),
        x='ìœ„ì¹˜',
        y='price_cleaned',
        title='ì§€ì—­ë³„ ëŒ€í‘œ ì˜µì…˜ ê°€ê²© í‰ê· ',
        labels={'price_cleaned': 'ê°€ê²© (ì›)', 'ìœ„ì¹˜': 'ì§€ì—­'}
    )
    
    fig_price.update_layout(
        xaxis_tickangle=-45,
        yaxis_title='í‰ê·  ê°€ê²© (ì›)',
        showlegend=False
    )
    
    return fig_price

def validate_data(df):
    required_columns = ['hospital_name', 'location', 'event_name', 'option_name', 
                       'price', 'rating', 'review_count', 'scrap_count', 'inquiry_count']
    
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        st.warning(f"ëˆ„ë½ëœ ì»¬ëŸ¼ì´ ìˆìŠµë‹ˆë‹¤: {', '.join(missing_columns)}")
        return False
    return True

def analyze_with_claude(df):
    try:
        anthropic = Anthropic(api_key=os.getenv("CLAUDE_API_KEY"))
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        analysis_data = df.copy()
        analysis_data['exposure_order'] = analysis_data.index + 1
        
        prompt = f"""
        ì—¬ì‹ í‹°ì¼“ì˜ ì‹œìˆ  ì´ë²¤íŠ¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬, ìƒˆë¡œìš´ ì´ë²¤íŠ¸ë¥¼ ë“±ë¡í•˜ë ¤ëŠ” ë³‘ì›ì—ê²Œ ë„ì›€ì´ ë  ë§Œí•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
        
        ì•„ë˜ í˜•ì‹ì— ë§ì¶° ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        A. ì˜µì…˜ ë¶„ì„
        1. ì˜µì…˜ëª… íŒ¨í„´ ë¶„ì„
        2. ê°€ê²©ëŒ€ë³„ ì˜µì…˜ êµ¬ì„± íŠ¹ì§•
        3. í‰ê·  ì˜µì…˜ ê°œìˆ˜ ë¶„ì„
        
        B. ì²« ë²ˆì§¸ ì˜µì…˜ ë¶„ì„
        1. ì¼ë°˜ì ì¸ ì²« ë²ˆì§¸ ì˜µì…˜ íŒ¨í„´
        2. ê°€ê²© ë¹„êµ
        
        C. ìœ„ì¹˜ ê¸°ë°˜ ë¶„ì„
        1. ì§€ì—­ë³„ íŠ¹ì„±
        
        D. ê³ ê° ë°˜ì‘ ë¶„ì„
        1. ê³ ê° ë°˜ì‘ ìƒì„¸ ë¶„ì„
        
        ë¶„ì„ ì‹œ ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì„ ì¤€ìˆ˜í•´ì£¼ì„¸ìš”:
        1. ì‹¤ì œ ì˜ˆì‹œì™€ ìˆ˜ì¹˜ë¥¼ ê·¼ê±°ë¡œ ë“¤ì–´ ë¶„ì„í•´ì£¼ì„¸ìš”.
        2. ê°€ê²©ì— ëŒ€í•œ ë¶„ì„ì„ í•  ë•Œì—ëŠ” ì •í™•í•œ ê¸ˆì•¡ê³¼ ì‹¤ì œ ì˜ˆì‹œë¥¼ ë“¤ì–´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        3. ë¶„ì„í•  ë•Œ ì£¼ì˜ì‚¬í•­:
            - ê°€ê²©ì´ë‚˜ ìš©ëŸ‰ì˜ ë²”ìœ„ë¥¼ í‘œí˜„í•  ë•ŒëŠ” '~' ëŒ€ì‹  'ë¶€í„°', 'ê¹Œì§€' ë˜ëŠ” '-' ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.
        
        ë§ˆì§€ë§‰ìœ¼ë¡œ, 3ê°€ì§€ í•µì‹¬ ì œì–¸ì„ í•´ì£¼ì„¸ìš”.
        
        ë°ì´í„°:
        {analysis_data.to_string()}
        """
        
        response = anthropic.messages.create(
            model="claude-3-sonnet-20240229",
            max_tokens=2000,
            temperature=0,
            messages=[{"role": "user", "content": prompt}]
        )
        
        try:
            content = response.content[0].text if isinstance(response.content, list) else response.content
            
            st.header("ğŸ” AI ë¶„ì„ ê²°ê³¼")
            
            sections = {
                "A": "ì˜µì…˜ ë¶„ì„ ğŸ“Š",
                "B": "ì²« ë²ˆì§¸ ì˜µì…˜ ë¶„ì„ ğŸ’°",
                "C": "ìœ„ì¹˜ ê¸°ë°˜ ë¶„ì„ ğŸ“",
                "D": "ê³ ê° ë°˜ì‘ ë¶„ì„ ğŸ‘¥"
            }
            
            for section, title in sections.items():
                st.subheader(f"{title}")
                section_start = content.find(f"{section}.")
                section_end = content.find(f"{chr(ord(section)+1)}.") if section != "D" else content.find("ë§ˆì§€ë§‰ìœ¼ë¡œ")
                
                if section_start != -1:
                    section_content = content[section_start:section_end].strip()
                    st.markdown(section_content)
            
            # í•µì‹¬ ì œì–¸ í‘œì‹œ
            if "í•µì‹¬ ì œì–¸" in content:
                st.subheader("ğŸ’¡ ìƒˆë¡œìš´ ì´ë²¤íŠ¸ ë“±ë¡ì„ ìœ„í•œ í•µì‹¬ ì œì–¸")
                recommendations = content[content.find("í•µì‹¬ ì œì–¸"):].split("\n")
                for rec in recommendations[1:]:
                    if rec.strip():
                        st.info(rec.strip())
            
            return content
            
        except Exception as e:
            st.error(f"ë¶„ì„ ê²°ê³¼ í‘œì‹œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return "ë¶„ì„ ê²°ê³¼ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
    except Exception as e:
        st.error(f"Claude AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return "ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def generate_pdf(df, analysis_text):
    try:
        buffer = io.BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4)
        
        # ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ê²½ë¡œ ì§€ì • ë° ë“±ë¡
        FONT_PATH = os.path.join(os.path.dirname(__file__), "NanumGothic.ttf")
        try:
            pdfmetrics.registerFont(TTFont('NanumGothic', FONT_PATH))
            registerFontFamily('NanumGothic', normal='NanumGothic')
            font_name = 'NanumGothic'
        except Exception as e:
            st.warning(f"í°íŠ¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            font_name = 'Helvetica'
        
        # í•œê¸€ ì§€ì› ìŠ¤íƒ€ì¼ ìƒì„±
        styles = getSampleStyleSheet()
        styles.add(ParagraphStyle(
            name='KoreanNormal',
            fontName=font_name,
            fontSize=10,
            leading=12
        ))
        styles.add(ParagraphStyle(
            name='KoreanHeading1',
            fontName=font_name,
            fontSize=16,
            leading=20,
            spaceAfter=30
        ))
        
        elements = []
        
        # ì œëª© ì¶”ê°€
        elements.append(Paragraph('ìŠ¤í¬ë˜í•‘ ë°ì´í„°', styles['KoreanHeading1']))
        elements.append(Spacer(1, 20))
        
        # ë°ì´í„° í…Œì´ë¸” ìƒì„±
        col_names = {
            'hospital_name': 'ë³‘ì›ëª…',
            'location': 'ìœ„ì¹˜',
            'event_name': 'ì´ë²¤íŠ¸ëª…',
            'option_name': 'ì˜µì…˜ëª…',
            'price': 'ê°€ê²©',
            'rating': 'í‰ì ',
            'review_count': 'ë¦¬ë·°ìˆ˜',
            'scrap_count': 'ìŠ¤í¬ë©ìˆ˜',
            'inquiry_count': 'ë¬¸ì˜ìˆ˜'
        }
        
        table_data = [[col_names[col] for col in col_names.keys()]]
        
        for _, row in df.iterrows():
            table_row = []
            for col in col_names.keys():
                try:
                    value = row[col] if pd.notna(row[col]) else "N/A"
                    table_row.append(str(value)[:20])
                except KeyError:
                    table_row.append('N/A')
            table_data.append(table_row)
        
        table_style = TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), font_name),
            ('FONTSIZE', (0, 0), (-1, 0), 12),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('TEXTCOLOR', (0, 1), (-1, -1), colors.black),
            ('FONTNAME', (0, 1), (-1, -1), font_name),
            ('FONTSIZE', (0, 1), (-1, -1), 10),
            ('GRID', (0, 0), (-1, -1), 1, colors.black),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
        ])
        
        table = Table(table_data, repeatRows=1)
        table.setStyle(table_style)
        elements.append(table)
        
        # ë¶„ì„ ë¦¬í¬íŠ¸
        elements.append(Spacer(1, 30))
        elements.append(Paragraph('ë¶„ì„ ë¦¬í¬íŠ¸', styles['KoreanHeading1']))
        elements.append(Paragraph(analysis_text, styles['KoreanNormal']))
        
        # PDF ìƒì„±
        doc.build(elements)
        pdf_bytes = buffer.getvalue()
        buffer.close()
        return pdf_bytes
        
    except Exception as e:
        st.error(f"PDF ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

def main():
    st.title("ì—¬ì‹ í‹°ì¼“ ë°ì´í„° ìŠ¤í¬ë˜í¼")
    
    keyword = st.text_input("ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
    
    if st.button("ìŠ¤í¬ë˜í•‘ ì‹œì‘"):
        progress_bar = st.progress(0)
        scraper = YeoshinScraper()
        
        with st.spinner('ë°ì´í„°ë¥¼ ìˆ˜ì§‘ì¤‘ì…ë‹ˆë‹¤...'):
            df = scraper.scrape_data(keyword, progress_bar)
            
        if not df.empty and validate_data(df):
            st.success("ë°ì´í„° ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # ì¹¼ëŸ¼ëª…ì„ í•œê¸€ë¡œ ë³€ê²½
            column_names = {
                'hospital_name': 'ë³‘ì›ëª…',
                'location': 'ìœ„ì¹˜',
                'event_name': 'ì´ë²¤íŠ¸ëª…',
                'option_name': 'ì˜µì…˜ëª…',
                'price': 'ê°€ê²©',
                'rating': 'í‰ì ',
                'review_count': 'ë¦¬ë·°ìˆ˜',
                'scrap_count': 'ìŠ¤í¬ë©ìˆ˜',
                'inquiry_count': 'ë¬¸ì˜ìˆ˜',
                'detail_link': 'ìƒì„¸ë§í¬'
            }
            df = df.rename(columns=column_names)
            
            # ë°ì´í„°í”„ë ˆì„ì„ ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ ì»¨í…Œì´ë„ˆì— í‘œì‹œ
            st.write("ìˆ˜ì§‘ëœ ë°ì´í„°:")
            st.dataframe(df, height=400)
            
            # ì‹œê°í™”
            fig_price = create_visualizations(df)
            st.plotly_chart(fig_price)
            
            # Claude AI ë¶„ì„
            with st.spinner('AI ë¶„ì„ì„ ìˆ˜í–‰ì¤‘ì…ë‹ˆë‹¤...'):
                analysis_text = analyze_with_claude(df)
                      
            try:
                pdf_bytes = generate_pdf(df, analysis_text)
                if pdf_bytes:
                    st.download_button(
                        label="PDF ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                        data=pdf_bytes,
                        file_name=f"yeoshin_{keyword}_report.pdf",
                        mime="application/pdf"
                    )
                else:
                    st.error("PDF ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        else:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ë°ì´í„° í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")

if __name__ == "__main__":
    main()
